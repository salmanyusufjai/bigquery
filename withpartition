from google.cloud import bigquery
from google.auth import load_credentials_from_file
from datetime import datetime
import pandas as pd

# Path to your user authentication JSON file
user_auth_file = 'path/to/your/user_authentication.json'

# Load credentials from the user authentication JSON file
credentials, project_id = load_credentials_from_file(user_auth_file)

# Initialize BigQuery client with user credentials
client = bigquery.Client(credentials=credentials, project=project_id)

# Function to convert dd/mm/yyyy format to timestamp
def convert_to_timestamp(date_string):
    return datetime.strptime(date_string, '%d/%m/%Y')

# Function to fetch data using parameterized queries with dynamic project and dataset
def fetch_data_with_parameters(query, params):
    job_config = bigquery.QueryJobConfig(query_parameters=params)
    query_job = client.query(query, job_config=job_config)
    return query_job.result().to_dataframe()

# Function to determine the partition date based on the dictionary
def determine_partition_date(processing_date, partition_dict):
    for entry in partition_dict:
        dict_date = datetime.strptime(entry['date'], '%d%m%Y')
        snap_date = datetime.strptime(entry['snap'], '%Y%m')
        snapbefore_date = datetime.strptime(entry['snapbefore'], '%Y%m')
        
        if processing_date.year == snap_date.year and processing_date.month == snap_date.month:
            if processing_date > dict_date:
                return snapbefore_date.replace(day=1)
            else:
                return snap_date.replace(day=1)
    return processing_date.replace(day=1)

# Query the main table with dynamic project and dataset
def query_main_table(project, dataset):
    query = f"""
    SELECT entity_key, company_number, processingdate, other_fields
    FROM `{project}.{dataset}.main_table`
    """
    return client.query(query).result().to_dataframe()

# Fetch holdingco and holdtype from the holgroup table with dynamic project and dataset
def fetch_holgroup_data(project, dataset, main_table, partition_dict):
    main_table['processingdate'] = main_table['processingdate'].apply(convert_to_timestamp)
    partition_dates = main_table['processingdate'].apply(lambda x: determine_partition_date(x, partition_dict))

    query = f"""
    SELECT company_number, holdingco, holdtype
    FROM (
        SELECT company_number, holdingco, holdtype, ROW_NUMBER() OVER (PARTITION BY company_number ORDER BY createdate DESC, createtime DESC) as rn
        FROM `{project}.{dataset}.holgroup`
        WHERE company_number IN UNNEST(@company_numbers)
        AND _PARTITIONTIME <= TIMESTAMP(@processing_date)
    )
    WHERE rn = 1
    """
    params = [
        bigquery.ArrayQueryParameter("company_numbers", "STRING", main_table['company_number'].tolist()),
        bigquery.ScalarQueryParameter("processing_date", "TIMESTAMP", partition_dates.max())
    ]
    return fetch_data_with_parameters(query, params)

# Function to fetch and merge additional data from other tables with dynamic project and dataset
def fetch_and_merge_data(main_table, table_name, key_field, additional_fields, partition_dict):
    main_table['processingdate'] = main_table['processingdate'].apply(convert_to_timestamp)
    partition_dates = main_table['processingdate'].apply(lambda x: determine_partition_date(x, partition_dict))

    query_template = f"""
    SELECT {key_field}, {', '.join(additional_fields)}
    FROM (
        SELECT {key_field}, {', '.join(additional_fields)}, ROW_NUMBER() OVER (PARTITION BY {key_field} ORDER BY createdate DESC, createtime DESC) as rn
        FROM `{project_id}.{{dataset}}.{table_name}`
        WHERE {key_field} IN UNNEST(@keys)
        AND _PARTITIONTIME <= TIMESTAMP(@processing_date)
    )
    WHERE rn = 1
    """
    params = [
        bigquery.ArrayQueryParameter("keys", "STRING", main_table[key_field].dropna().tolist()),
        bigquery.ScalarQueryParameter("processing_date", "TIMESTAMP", partition_dates.max())
    ]
    query = query_template.format(dataset=dataset)
    return fetch_data_with_parameters(query, params)

# Main execution flow
if __name__ == "__main__":
    try:
        # Example dynamic project and dataset names
        main_project = 'your_main_project_id'
        main_dataset = 'your_main_dataset'
        holgroup_project = 'your_holgroup_project_id'
        holgroup_dataset = 'your_holgroup_dataset'

        # Sample partition dictionary
        partition_dict = [
            {"date":"18032024", "snap":"202403", "snapbefore":"202402"},
            {"date":"20022024", "snap":"202402", "snapbefore":"202401"},
            {"date":"21012024", "snap":"202401", "snapbefore":"202312"}
        ]

        # Query main table
        main_table = query_main_table(main_project, main_dataset)

        # Fetch and merge holgroup data
        holgroup_data = fetch_holgroup_data(holgroup_project, holgroup_dataset, main_table, partition_dict)
        if not holgroup_data.empty:
            main_table = main_table.merge(holgroup_data, on='company_number', how='left')

        # Fetch and merge additional data from scorecheck, acl, protectscore
        tables_to_fetch = [('scorecheck', 'company_number', ['score', 'grade']),
                           ('acl', 'company_number', ['finallimit']),
                           ('protectscore', 'company_number', ['pscore'])]

        for table_name, key_field, additional_fields in tables_to_fetch:
            data = fetch_and_merge_data(main_table, table_name, key_field, additional_fields, partition_dict)
            if not data.empty:
                main_table = main_table.merge(data, on=key_field, how='left')

        # Fetch and merge UHC data from scorecheck, acl, protectscore
        uhc_tables_to_fetch = [('scorecheck', 'holdingco', ['score as uhc_score', 'grade as uhc_grade']),
                               ('acl', 'holdingco', ['finallimit as uhc_limit']),
                               ('protectscore', 'holdingco', ['pscore as uhc_protectscore'])]

        for table_name, key_field, additional_fields in uhc_tables_to_fetch:
            uhc_data = fetch_and_merge_data(main_table, table_name, key_field, additional_fields, partition_dict)
            if not uhc_data.empty:
                main_table = main_table.merge(uhc_data, on=key_field, how='left')

        # Print or further process main_table with all merged data
        print(main_table.head())

    except Exception as e:
        print(f"Error in main execution flow: {str(e)}")
